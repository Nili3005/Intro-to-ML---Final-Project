{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nili3005/ML/blob/main/Project_Demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade ngboost\n",
        "!pip install ucimlrepo"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uEiQTmeWako1",
        "outputId": "239024d2-8cfa-4685-9ca4-c4f28509c849"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ngboost in /usr/local/lib/python3.10/dist-packages (0.4.2)\n",
            "Requirement already satisfied: lifelines>=0.25 in /usr/local/lib/python3.10/dist-packages (from ngboost) (0.27.8)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from ngboost) (1.23.5)\n",
            "Requirement already satisfied: scikit-learn>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from ngboost) (1.2.2)\n",
            "Requirement already satisfied: scipy>=1.7.2 in /usr/local/lib/python3.10/dist-packages (from ngboost) (1.11.4)\n",
            "Requirement already satisfied: tqdm>=4.3 in /usr/local/lib/python3.10/dist-packages (from ngboost) (4.66.1)\n",
            "Requirement already satisfied: pandas>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from lifelines>=0.25->ngboost) (1.5.3)\n",
            "Requirement already satisfied: matplotlib>=3.0 in /usr/local/lib/python3.10/dist-packages (from lifelines>=0.25->ngboost) (3.7.1)\n",
            "Requirement already satisfied: autograd>=1.5 in /usr/local/lib/python3.10/dist-packages (from lifelines>=0.25->ngboost) (1.6.2)\n",
            "Requirement already satisfied: autograd-gamma>=0.3 in /usr/local/lib/python3.10/dist-packages (from lifelines>=0.25->ngboost) (0.5.0)\n",
            "Requirement already satisfied: formulaic>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from lifelines>=0.25->ngboost) (0.6.6)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0.2->ngboost) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0.2->ngboost) (3.2.0)\n",
            "Requirement already satisfied: future>=0.15.2 in /usr/local/lib/python3.10/dist-packages (from autograd>=1.5->lifelines>=0.25->ngboost) (0.18.3)\n",
            "Requirement already satisfied: astor>=0.8 in /usr/local/lib/python3.10/dist-packages (from formulaic>=0.2.2->lifelines>=0.25->ngboost) (0.8.1)\n",
            "Requirement already satisfied: interface-meta>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from formulaic>=0.2.2->lifelines>=0.25->ngboost) (1.3.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from formulaic>=0.2.2->lifelines>=0.25->ngboost) (4.5.0)\n",
            "Requirement already satisfied: wrapt>=1.0 in /usr/local/lib/python3.10/dist-packages (from formulaic>=0.2.2->lifelines>=0.25->ngboost) (1.14.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0->lifelines>=0.25->ngboost) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0->lifelines>=0.25->ngboost) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0->lifelines>=0.25->ngboost) (4.45.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0->lifelines>=0.25->ngboost) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0->lifelines>=0.25->ngboost) (23.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0->lifelines>=0.25->ngboost) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0->lifelines>=0.25->ngboost) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0->lifelines>=0.25->ngboost) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.0->lifelines>=0.25->ngboost) (2023.3.post1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.0->lifelines>=0.25->ngboost) (1.16.0)\n",
            "Requirement already satisfied: ucimlrepo in /usr/local/lib/python3.10/dist-packages (0.0.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6v68EV_fYGBt"
      },
      "source": [
        "# Usage\n",
        "\n",
        "We'll start with a probabilistic regression example on the Boston housing dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "tags": [
          "remove_cell"
        ],
        "id": "B69cHiqVYGBw"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.append('/Users/c242587/Desktop/projects/git/ngboost')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "wF7W2EDIYGBx",
        "outputId": "240df28d-10d8-47ad-e3c7-c0e6930a7acd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[iter 0] loss=3.6105 val_loss=0.0000 scale=1.0000 norm=6.5637\n",
            "[iter 100] loss=2.6907 val_loss=0.0000 scale=2.0000 norm=4.8416\n",
            "[iter 200] loss=2.1434 val_loss=0.0000 scale=2.0000 norm=3.3526\n",
            "[iter 300] loss=1.8739 val_loss=0.0000 scale=2.0000 norm=2.9165\n",
            "[iter 400] loss=1.7540 val_loss=0.0000 scale=1.0000 norm=1.3672\n",
            "Test MSE 34.5570327053653\n",
            "Test NLL 5.837848632778266\n"
          ]
        }
      ],
      "source": [
        "from ngboost import NGBRegressor\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "#from sklearn.datasets import load_boston\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "#X, Y = load_boston(True)\n",
        "data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
        "raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
        "X = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
        "Y = raw_df.values[1::2, 2]\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2)\n",
        "\n",
        "ngb = NGBRegressor().fit(X_train, Y_train)\n",
        "Y_preds = ngb.predict(X_test)\n",
        "Y_dists = ngb.pred_dist(X_test)\n",
        "\n",
        "# test Mean Squared Error\n",
        "test_MSE = mean_squared_error(Y_preds, Y_test)\n",
        "print('Test MSE', test_MSE)\n",
        "\n",
        "# test Negative Log Likelihood\n",
        "test_NLL = -Y_dists.logpdf(Y_test).mean()\n",
        "print('Test NLL', test_NLL)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yfLWEN1-YGBy"
      },
      "source": [
        "Getting the estimated distributional parameters at a set of points is easy. This returns the predicted mean and standard deviation of the first five observations in the test set:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "IhCybQf8YGBz",
        "outputId": "8da38397-dca3-4f2a-9d74-fa688ce93e7d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'loc': array([18.7337793 , 25.75646452, 16.30144809, 21.1754274 , 28.67135959]),\n",
              " 'scale': array([1.43474407, 1.4659151 , 1.42869714, 1.36461256, 1.12869781])}"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "Y_dists[0:5].params"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UNBbqxuMYGBz"
      },
      "source": [
        "## Distributions\n",
        "\n",
        "NGBoost can be used with a variety of distributions, broken down into those for regression (support on an infinite set) and those for classification (support on a finite set)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZkmsiM1JYGB0"
      },
      "source": [
        "### Regression Distributions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ebYJtImvYGB0"
      },
      "source": [
        "| Distribution | Parameters | Implemented Scores | Reference |\n",
        "| --- | --- | --- | --- |\n",
        "| `Normal` | `loc`, `scale` | `LogScore`, `CRPScore` | [`scipy.stats` normal](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.norm.html) |\n",
        "| `LogNormal` | `s`, `scale` | `LogScore`, `CRPScore` | [`scipy.stats` lognormal](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.lognorm.html) |\n",
        "| `Exponential` | `scale` | `LogScore`, `CRPScore` | [`scipy.stats` exponential](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.expon.html) |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eUp6rX89YGB1"
      },
      "source": [
        "Regression distributions can be used through the `NGBRegressor()` constructor by passing the appropriate class as the `Dist` argument. `Normal` is the default."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "SzD8-SUVYGB1"
      },
      "outputs": [],
      "source": [
        "from ngboost.distns import Exponential, Normal\n",
        "\n",
        "#X, Y = load_boston(True)\n",
        "X_reg_train, X_reg_test, Y_reg_train, Y_reg_test = train_test_split(X, Y, test_size=0.2)\n",
        "\n",
        "ngb_norm = NGBRegressor(Dist=Normal, verbose=False).fit(X_reg_train, Y_reg_train)\n",
        "ngb_exp = NGBRegressor(Dist=Exponential, verbose=False).fit(X_reg_train, Y_reg_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ihXJ8b0aYGB1"
      },
      "source": [
        "There are two prediction methods for `NGBRegressor` objects: `predict()`, which returns point predictions as one would expect from a standard regressor, and `pred_dist()`, which returns a distribution object representing the conditional distribution of $Y|X=x_i$ at the points $x_i$ in the test set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "mYWitZ9OYGB1",
        "outputId": "b2c25798-e786-43b7-c042-cd0ae7e11830",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([22.37312499, 15.70084963, 17.8926069 , 35.34675615, 20.29360037])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "ngb_norm.predict(X_reg_test)[0:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "5HgrqhoMYGB2",
        "outputId": "a2169fe5-8f3a-4fc6-9f50-cf999218924c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([24.36977245, 12.94774469, 17.8683958 , 34.98104835, 20.85635175])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "ngb_exp.predict(X_reg_test)[0:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "8HDlzrWNYGB2",
        "outputId": "0f468f96-2389-448e-f6a0-1eb71f228c4f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'scale': array([24.36977245, 12.94774469, 17.8683958 , 34.98104835, 20.85635175])}"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "ngb_exp.pred_dist(X_reg_test)[0:5].params"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ZlBmH1KYGB2"
      },
      "source": [
        "#### Survival Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zn7FxIO6YGB3"
      },
      "source": [
        "NGBoost supports analyses of right-censored data. Any distribution that can be used for regression in NGBoost can also be used for survival analysis in theory, but this requires the implementation of the right-censored version of the appropriate score. At the moment, `LogNormal` and `Exponential` have these scores implemented. To do survival analysis, use `NGBSurvival` and pass both the time-to-event (or censoring) and event indicator vectors to  `fit()`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "byYiYJ5jYGB3",
        "outputId": "e2118bf1-e472-4ede-87a2-fffe757713de",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[iter 0] loss=1.2737 val_loss=0.0000 scale=4.0000 norm=2.3241\n",
            "[iter 100] loss=0.5565 val_loss=0.0000 scale=2.0000 norm=0.9015\n",
            "[iter 200] loss=0.2995 val_loss=0.0000 scale=2.0000 norm=0.4947\n",
            "[iter 300] loss=0.0591 val_loss=0.0000 scale=4.0000 norm=0.5065\n",
            "[iter 400] loss=-0.0938 val_loss=0.0000 scale=2.0000 norm=0.2078\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from ngboost import NGBSurvival\n",
        "from ngboost.distns import LogNormal\n",
        "\n",
        "#X, Y = load_boston(True)\n",
        "X_surv_train, X_surv_test, Y_surv_train, Y_surv_test = train_test_split(X, Y, test_size=0.2)\n",
        "\n",
        "# introduce administrative censoring to simulate survival data\n",
        "T_surv_train = np.minimum(Y_surv_train, 30) # time of an event or censoring\n",
        "E_surv_train = Y_surv_train > 30 # 1 if T[i] is the time of an event, 0 if it's a time of censoring\n",
        "\n",
        "ngb = NGBSurvival(Dist=LogNormal).fit(X_surv_train, T_surv_train, E_surv_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5rvKBR02YGB3"
      },
      "source": [
        "The scores currently implemented assume that the censoring is independent of survival, conditional on the observed predictors."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R0KnXB22YGB3"
      },
      "source": [
        "### Classification Distributions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dv67RKIFYGB3"
      },
      "source": [
        "| Distribution | Parameters | Implemented Scores | Reference |\n",
        "| --- | --- | --- | --- |\n",
        "| `k_categorical(K)` | `p0`, `p1`... `p{K-1}` | `LogScore` | [Categorical distribution on Wikipedia](https://en.wikipedia.org/wiki/Categorical_distribution) |\n",
        "| `Bernoulli` | `p` | `LogScore` | [Bernoulli distribution on Wikipedia](https://en.wikipedia.org/wiki/Bernoulli_distribution) |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2oEgUThdYGB3"
      },
      "source": [
        "Classification distributions can be used through the `NGBClassifier()` constructor by passing the appropriate class as the `Dist` argument. `Bernoulli` is the default and is equivalent to `k_categorical(2)`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "o__ZxDBFYGB3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "outputId": "9bc06c5e-6894-4cc8-e315-408a59c58aa3"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-a3c10cdaab8c>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_breast_cancer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_breast_cancer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;31m# artificially make this a 3-class problem instead of a 2-class problem\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mX_cls_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_cls_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_cls_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_cls_test\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: load_breast_cancer() takes 0 positional arguments but 1 was given"
          ]
        }
      ],
      "source": [
        "from ngboost import NGBClassifier\n",
        "from ngboost.distns import k_categorical, Bernoulli\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "\n",
        "X, y = load_breast_cancer(True)\n",
        "y[0:15] = 2 # artificially make this a 3-class problem instead of a 2-class problem\n",
        "X_cls_train, X_cls_test, Y_cls_train, Y_cls_test  = train_test_split(X, y, test_size=0.2)\n",
        "\n",
        "ngb_cat = NGBClassifier(Dist=k_categorical(3), verbose=False) # tell ngboost that there are 3 possible outcomes\n",
        "_ = ngb_cat.fit(X_cls_train, Y_cls_train) # Y should have only 3 values: {0,1,2}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sdD9ivqlYGB4"
      },
      "source": [
        "When using NGBoost for classification, the outcome vector `Y` must consist only of integers from 0 to K-1, where K is the total number of classes. This is consistent with the classification standards in sklearn."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7FJRaHbGYGB4"
      },
      "source": [
        "`NGBClassifier` objects have three prediction methods: `predict()` returns the most likely class, `predict_proba()` returns the class probabilities, and `pred_dist()` returns the distribution object."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dajpHilnYGB4"
      },
      "outputs": [],
      "source": [
        "ngb_cat.predict(X_cls_test)[0:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a3Gm328uYGB4"
      },
      "outputs": [],
      "source": [
        "ngb_cat.predict_proba(X_cls_test)[0:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RILuySxqYGB4"
      },
      "outputs": [],
      "source": [
        "ngb_cat.pred_dist(X_cls_test)[0:5].params"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jgVVFFOQYGB4"
      },
      "source": [
        "## Scores"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LoEiDd5bYGB4"
      },
      "source": [
        "NGBoost supports the log score (`LogScore`, also known as negative log-likelihood) and CRPS (`CRPScore`), although each score may not be implemented for each distribution. The score is specified by the `Score` argument in the constructor."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "hide_output"
        ],
        "id": "KCb4GcT3YGB4"
      },
      "outputs": [],
      "source": [
        "from ngboost.scores import LogScore, CRPScore\n",
        "\n",
        "NGBRegressor(Dist=Exponential, Score=CRPScore, verbose=False).fit(X_reg_train, Y_reg_train)\n",
        "NGBClassifier(Dist=k_categorical(3), Score=LogScore, verbose=False).fit(X_cls_train, Y_cls_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TuWNTQVIYGB5"
      },
      "source": [
        "## Base Learners"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hvGbzOC7YGB5"
      },
      "source": [
        "NGBoost can be used with any sklearn regressor as the base learner, specified with the `Base` argument. The default is a depth-3 regression tree."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "hide_output"
        ],
        "id": "-6L6fzDPYGB5"
      },
      "outputs": [],
      "source": [
        "from sklearn.tree import DecisionTreeRegressor\n",
        "\n",
        "learner = DecisionTreeRegressor(criterion='friedman_mse', max_depth=5)\n",
        "\n",
        "NGBSurvival(Dist=Exponential, Score=CRPScore, Base=learner, verbose=False).fit(X_surv_train, T_surv_train, E_surv_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KI-jzSz8YGB5"
      },
      "source": [
        "## Other Arguments"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RYJc7c4gYGB5"
      },
      "source": [
        "The learning rate, number of estimators, minibatch fraction, and column subsampling are also easily adjusted:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "hide_output"
        ],
        "id": "3r-naJj-YGB5"
      },
      "outputs": [],
      "source": [
        "ngb = NGBRegressor(n_estimators=100, learning_rate=0.01,\n",
        "             minibatch_frac=0.5, col_sample=0.5)\n",
        "ngb.fit(X_reg_train, Y_reg_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JzIKH4epYGB5"
      },
      "source": [
        "Sample weights (for training) are set using the `sample_weight` argument to `fit`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "hide_output"
        ],
        "id": "WOudBxY5YGB6"
      },
      "outputs": [],
      "source": [
        "ngb = NGBRegressor(n_estimators=100, learning_rate=0.01,\n",
        "             minibatch_frac=0.5, col_sample=0.5)\n",
        "weights = np.random.random(Y_reg_train.shape)\n",
        "ngb.fit(X_reg_train, Y_reg_train, sample_weight=weights)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}